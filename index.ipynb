{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "miniproject2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnAEU9iKUmFl"
      },
      "source": [
        "# Miniproject: Image Classification\n",
        "\n",
        "### Description\n",
        "\n",
        "One of the oldest traditions in deep learning is to first tackle the fun problem of MNIST classification. [The MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) is a large database of handwritten digits that is commonly used as a first test for new classification algorithms. \n",
        "We follow this tradition to investigate the performance of artificial neural networks of different complexity on MNIST. However, since MNIST is too easy for accessing the full power of modern machine learning algorithms (see e.g. [this post](https://twitter.com/goodfellow_ian/status/852591106655043584)) we will extend our analysis to the recently introduced, harder [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist).\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "- You should have a running installation of [tensorflow](https://www.tensorflow.org/install/) and [keras](https://keras.io/). Feel free to gain inspiration from the [Keras example directory](https://keras.io/examples/) for your implementations.\n",
        "- You should know the concepts \"multilayer perceptron\", \"stochastic gradient descent with minibatches\", \"Adam\", \"convolutional neural network\", \"training and validation data\", \"overfitting\", \"regularization\", and \"early stopping\".\n",
        "\n",
        "### What you will learn\n",
        "\n",
        "- You will learn how to define feedforward neural networks in keras and fit them to data (i.e. training).\n",
        "- You will be guided through a prototyping procedure for the application of deep learning to a specific domain.\n",
        "- You will gain some experience on the influence of network architecture, optimizer and regularization choices on the goodness of fit.\n",
        "- You will learn to be more patient :) Some fits may take your computer quite a bit of time; run them over night (or on an external server).\n",
        "\n",
        "### Evaluation criteria\n",
        "\n",
        "The evaluation is (mostly) based on the figures you submit and your answer sentences. Provide clear and concise answers respecting the indicated maximum length.\n",
        "\n",
        "**The submitted notebook must be run by you!** We will only do random tests of your code and not re-run the full notebook. There will be fraud detection sessions at the end of the semester.\n",
        "\n",
        "### Your names\n",
        "\n",
        "**Before you start**: please enter your full name(s) in the field below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-03-09T09:08:24.514461Z",
          "start_time": "2018-03-09T09:08:24.506410Z"
        },
        "id": "bVa5G9-6UmFv"
      },
      "source": [
        "student1 = \"Jan Bauer (18-764-571)\"\n",
        "student2 = \"Adrien Bertaud (Sciper 324795)\""
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-02-22T21:52:59.697375Z",
          "start_time": "2018-02-22T21:52:59.689443Z"
        },
        "id": "8ZLXwbYkUmFy"
      },
      "source": [
        "## Some helper functions\n",
        "\n",
        "For your convenience we provide here some functions to preprocess the data and plot the results later. Simply run the following cells with `Shift-Enter`.\n",
        "\n",
        "### Dependencies and constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-02-23T14:27:09.352019Z",
          "start_time": "2018-02-23T14:27:08.476310Z"
        },
        "id": "a_-AKt04UmFz"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "\n",
        "#import tensorflow and keras\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, History"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uByPWuGHUOb2",
        "outputId": "4df0e18e-297a-4a45-fea4-0eba96071c5e"
      },
      "source": [
        "print(\"Running tensorflow version: {0}\".format(tf.__version__))\n",
        "print(\"Running keras version: {0}\".format(keras.__version__))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running tensorflow version: 2.4.1\n",
            "Running keras version: 2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx8b9KUvUprh",
        "outputId": "895c332a-6d5a-42a7-a16a-6cb38f4276c1"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU') # True/False"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4cZmSgSYb2f"
      },
      "source": [
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "  strategy = tf.distribute.get_strategy() "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmyBZURoUOb3"
      },
      "source": [
        "# Define verbosity\n",
        "verbose = True"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-U_Ag8QUmFz"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-02-23T15:11:52.252208Z",
          "start_time": "2018-02-23T15:11:52.121360Z"
        },
        "id": "d2V7in4BUmF0"
      },
      "source": [
        "def plot_some_samples(x, y = [], yhat = [], select_from = [], \n",
        "                      ncols = 6, nrows = 4, xdim = 28, ydim = 28,\n",
        "                      label_mapping = range(10)):\n",
        "    \"\"\"plot some input vectors as grayscale images (optionally together with their assigned or predicted labels).\n",
        "    \n",
        "    x is an NxD - dimensional array, where D is the length of an input vector and N is the number of samples.\n",
        "    Out of the N samples, ncols x nrows indices are randomly selected from the list select_from (if it is empty, select_from becomes range(N)).\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(nrows, ncols)\n",
        "    if len(select_from) == 0:\n",
        "        select_from = range(x.shape[0])\n",
        "    indices = np.random.choice(select_from, size = min(ncols * nrows, len(select_from)), replace = False)\n",
        "    for i, ind in enumerate(indices):\n",
        "        thisax = ax[i//ncols,i%ncols]\n",
        "        thisax.matshow(x[ind].reshape(xdim, ydim), cmap='gray')\n",
        "        thisax.set_axis_off()\n",
        "        if len(y) != 0:\n",
        "            j = y[ind] if type(y[ind]) != np.ndarray else y[ind].argmax()\n",
        "            thisax.text(0, 0, (label_mapping[j]+1)%10, color='green', \n",
        "                                                       verticalalignment='top',\n",
        "                                                       transform=thisax.transAxes)\n",
        "        if len(yhat) != 0:\n",
        "            k = yhat[ind] if type(yhat[ind]) != np.ndarray else yhat[ind].argmax()\n",
        "            thisax.text(1, 0, (label_mapping[k]+1)%10, color='red',\n",
        "                                             verticalalignment='top',\n",
        "                                             horizontalalignment='right',\n",
        "                                             transform=thisax.transAxes)\n",
        "    return fig\n",
        "\n",
        "def prepare_standardplot(title, xlabel):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle(title)\n",
        "    ax1.set_ylabel('categorical cross entropy')\n",
        "    ax1.set_xlabel(xlabel)\n",
        "    ax1.set_yscale('log')\n",
        "    ax2.set_ylabel('accuracy [% correct]')\n",
        "    ax2.set_xlabel(xlabel)\n",
        "    return fig, ax1, ax2\n",
        "\n",
        "def finalize_standardplot(fig, ax1, ax2):\n",
        "    ax1handles, ax1labels = ax1.get_legend_handles_labels()\n",
        "    if len(ax1labels) > 0:\n",
        "        ax1.legend(ax1handles, ax1labels)\n",
        "    ax2handles, ax2labels = ax2.get_legend_handles_labels()\n",
        "    if len(ax2labels) > 0:\n",
        "        ax2.legend(ax2handles, ax2labels)\n",
        "    fig.tight_layout()\n",
        "    plt.subplots_adjust(top=0.9)\n",
        "\n",
        "def plot_history(history, title):\n",
        "    fig, ax1, ax2 = prepare_standardplot(title, 'epoch')\n",
        "    ax1.plot(history.history['loss'], label = \"train\")\n",
        "    ax1.plot(history.history['val_loss'], label = \"val\")\n",
        "    ax2.plot(history.history['accuracy'], label = \"train\")\n",
        "    ax2.plot(history.history['val_accuracy'], label = \"val\")\n",
        "    finalize_standardplot(fig, ax1, ax2)\n",
        "    return fig\n",
        "\n",
        "def plot_history_cust(history, title):\n",
        "    fig, ax1, ax2 = prepare_standardplot(title, 'epoch')\n",
        "    ax1.plot(history['loss'], label = \"train\")\n",
        "    ax1.plot(history['val_loss'], label = \"val\")\n",
        "    ax2.plot(history['accuracy'], label = \"train\")\n",
        "    ax2.plot(history['val_accuracy'], label = \"val\")\n",
        "    finalize_standardplot(fig, ax1, ax2)\n",
        "    return fig\n",
        "\n",
        "def plot_some_samples_cust(x, y = [], yhat = [], select_from = [], \n",
        "                      ncols = 6, nrows = 4, xdim = 28, ydim = 28,\n",
        "                      label_mapping = range(10)):\n",
        "    \"\"\"plot some input vectors as grayscale images (optionally together with their assigned or predicted labels).\n",
        "    \n",
        "    x is an NxD - dimensional array, where D is the length of an input vector and N is the number of samples.\n",
        "    Out of the N samples, ncols x nrows indices are randomly selected from the list select_from (if it is empty, select_from becomes range(N)).\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(nrows, ncols)\n",
        "    if len(select_from) == 0:\n",
        "        select_from = range(x.shape[0])\n",
        "    indices = np.random.choice(select_from, size = min(ncols * nrows, len(select_from)), replace = False)\n",
        "    for i, ind in enumerate(indices):\n",
        "        thisax = ax[i//ncols,i%ncols]\n",
        "        thisax.matshow(x[ind].reshape(xdim, ydim), cmap='gray')\n",
        "        thisax.set_axis_off()\n",
        "        if len(y) != 0:\n",
        "            j = y[ind] if type(y[ind]) != np.ndarray else y[ind].argmax()\n",
        "            thisax.text(0, 0, label_mapping[j], color='green', \n",
        "                                                       verticalalignment='top',\n",
        "                                                       transform=thisax.transAxes)\n",
        "        if len(yhat) != 0:\n",
        "            k = yhat[ind] if type(yhat[ind]) != np.ndarray else yhat[ind].argmax()\n",
        "            thisax.text(1, 0, label_mapping[k], color='red',\n",
        "                                             verticalalignment='top',\n",
        "                                             horizontalalignment='right',\n",
        "                                             transform=thisax.transAxes)\n",
        "    return fig\n",
        "\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96-3BgpfUmF1"
      },
      "source": [
        "## Exercise 1: Data import and visualization (6 points)\n",
        "\n",
        "The datasets we use in this project (MNIST, Fashion-MNIST) consists of grayscale images with 28x28 pixels. \n",
        "The low resolution (and grayscale) of the images certainly misses some information that could be helpful for classifying the images. However, since the data has lower dimensionality due to the low resolution, the training converges faster. This is an advantage in situations like here (or generally when prototyping), where we want to try many different things without having to wait too long. \n",
        "\n",
        "1. As a warm-up exercise, use the importer to (down-)load the MNIST and Fashion-MNIST dataset. Assign useful variables to test & train images and labels for both datasets respectively. (2 pts)\n",
        "2. Use the function `plot_some_samples` defined above to plot some samples of the two datasets. What do the green digits at the bottom left of each image indicate? (2 pts)\n",
        "3. To prepare for training: 1. transform the labels to one hot coding, i.e. for 5 classes, label 2 becomes the vector [0, 0, 1, 0, 0] (you can use `utils.to_categorical` function from keras), and 2. reshape (flatten) the input images to input vectors and rescale the input data into the range [0,1]. (2 pts)\n",
        "\n",
        "*Hint*: Keras comes with a convenient in-built [data importer](https://keras.io/datasets/) for common datasets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGiMLZFXUmF2"
      },
      "source": [
        "**Answer to Question 2** (1 sentence):<br/>\n",
        "The green digit at the bottom left corresponds to '(label_mapping[j]+1)%10' (*true class label incremented by one and divided modulo 10*) and can be interpreted as the index of the digit with value 1 (all others at 0) for one hot encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGSLbCcbUmF2"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44GJq_o2BlkA"
      },
      "source": [
        "#### Exercise 1.1\n",
        "Load the MNIST and Fashion-MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-02-23T14:27:44.442862Z",
          "start_time": "2018-02-23T14:27:09.505547Z"
        },
        "id": "wjga3NseUmF3"
      },
      "source": [
        "import tensorflow as tf\n",
        "(x_mnist_train, y_mnist_train), (x_mnist_test, y_mnist_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "(x_mnist_fashion_train, y_mnist_fashion_train), (x_mnist_fashion_test, y_mnist_fashion_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK0e2jWyBxuY"
      },
      "source": [
        "#### Exercise 1.2\n",
        "Plot some samples of the two datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "E-tP-_yR_cIT",
        "outputId": "e6e2a0a8-5538-4a94-d178-24359c37ba86"
      },
      "source": [
        "print(\"MNIST\")\n",
        "plot_some_samples(x_mnist_train, y_mnist_train, ncols=6, nrows=4);"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 24 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "rM7sGUJ7CPXI",
        "outputId": "6c0c44f0-f4cf-415b-bca9-9cf7a0d1bdc7"
      },
      "source": [
        "print(\"Fashion-MNIST\")\n",
        "plot_some_samples(x_mnist_fashion_train, y_mnist_fashion_train, ncols=6, nrows=4);"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fashion-MNIST\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 24 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozrpz5-NB7wg"
      },
      "source": [
        "#### Exercise 1.3\n",
        "Prepare for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q_Rl6c-DV87",
        "outputId": "2cdc0425-d06c-4d45-c5cc-fe89d070e61a"
      },
      "source": [
        "# transform the labels to one hot coding\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_mnist_train_one_hot = to_categorical(y_mnist_train)\n",
        "y_mnist_test_one_hot = to_categorical(y_mnist_test)\n",
        "\n",
        "for i in range(5):\n",
        "    print(\"train : {0} => {1} \\ttest : {2} => {3}\".format(y_mnist_train[i], y_mnist_train_one_hot[i], y_mnist_test[i], y_mnist_test_one_hot[i]))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train : 5 => [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] \ttest : 7 => [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "train : 0 => [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \ttest : 2 => [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "train : 4 => [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] \ttest : 1 => [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "train : 1 => [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] \ttest : 0 => [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "train : 9 => [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \ttest : 4 => [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09HL6DMLN8uu",
        "outputId": "64142db6-b8e3-4fe3-ef72-c8895fe1cb13"
      },
      "source": [
        "y_mnist_fashion_train_one_hot = to_categorical(y_mnist_fashion_train)\n",
        "y_mnist_fashion_test_one_hot = to_categorical(y_mnist_fashion_test)\n",
        "\n",
        "for i in range(5):\n",
        "    print(\"train : {0} => {1} \\ttest : {2} => {3}\".format(y_mnist_fashion_train[i], y_mnist_fashion_train_one_hot[i], y_mnist_fashion_test[i], y_mnist_fashion_test_one_hot[i]))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train : 9 => [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \ttest : 9 => [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "train : 0 => [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \ttest : 2 => [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "train : 0 => [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \ttest : 1 => [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "train : 3 => [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] \ttest : 1 => [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "train : 0 => [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \ttest : 6 => [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whHrNeQiETo7",
        "outputId": "4be02b8a-fcfc-44f1-ee38-9dacb45cac0a"
      },
      "source": [
        "# reshape (flatten) the input images to input vectors\n",
        "print(\"MNIST\")\n",
        "original_mnist_train_shape = x_mnist_train.shape\n",
        "original_mnist_test_shape = x_mnist_test.shape\n",
        "x_mnist_train = x_mnist_train.reshape(x_mnist_train.shape[0], x_mnist_train.shape[1]*x_mnist_train.shape[2])\n",
        "x_mnist_test = x_mnist_test.reshape(x_mnist_test.shape[0], x_mnist_test.shape[1]*x_mnist_test.shape[2])\n",
        "print(\"Reshaped training data from {0} to {1}\".format(original_mnist_train_shape, x_mnist_train.shape))\n",
        "print(\"Reshaped test data from {0} to {1}\".format(original_mnist_test_shape, x_mnist_test.shape))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST\n",
            "Reshaped training data from (60000, 28, 28) to (60000, 784)\n",
            "Reshaped test data from (10000, 28, 28) to (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evnIslVWHHmz",
        "outputId": "0636dbd0-2fa4-4478-d8c7-6fd6341e8650"
      },
      "source": [
        "print(\"Fashion-MNIST\")\n",
        "original_train_shape = x_mnist_fashion_train.shape\n",
        "original_test_shape = x_mnist_fashion_test.shape\n",
        "x_mnist_fashion_train = x_mnist_fashion_train.reshape(x_mnist_fashion_train.shape[0], x_mnist_fashion_train.shape[1]*x_mnist_fashion_train.shape[2])\n",
        "x_mnist_fashion_test = x_mnist_fashion_test.reshape(x_mnist_fashion_test.shape[0], x_mnist_fashion_test.shape[1]*x_mnist_fashion_test.shape[2])\n",
        "print(\"Reshaped training data from {0} to {1}\".format(original_train_shape, x_mnist_fashion_train.shape))\n",
        "print(\"Reshaped test data from {0} to {1}\".format(original_test_shape, x_mnist_fashion_test.shape))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fashion-MNIST\n",
            "Reshaped training data from (60000, 28, 28) to (60000, 784)\n",
            "Reshaped test data from (10000, 28, 28) to (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tDl4RApFFV2",
        "outputId": "da2e8358-1f8d-45cc-95b0-edaf9dc965c9"
      },
      "source": [
        "# MNIST: rescale the input data into the range [0,1]\n",
        "max_grey_value = 255.0\n",
        "\n",
        "print(\"MNIST\")\n",
        "print(\"Max value in initial dataset (train/test):\", np.max(x_mnist_train), np.max(x_mnist_test))\n",
        "print(\"Min value in initial dataset (train/test):\", np.min(x_mnist_train), np.min(x_mnist_test))\n",
        "x_mnist_train = x_mnist_train / max_grey_value  \n",
        "x_mnist_test = x_mnist_test / max_grey_value \n",
        "print(\"Max value in rescaled dataset (train/test):\", np.max(x_mnist_train), np.max(x_mnist_test))\n",
        "print(\"Min value in rescaled dataset (train/test):\", np.min(x_mnist_train), np.min(x_mnist_test))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST\n",
            "Max value in initial dataset (train/test): 255 255\n",
            "Min value in initial dataset (train/test): 0 0\n",
            "Max value in rescaled dataset (train/test): 1.0 1.0\n",
            "Min value in rescaled dataset (train/test): 0.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xRmWrSuLyy5",
        "outputId": "03872832-5e1e-41a3-ed4c-b47ccfc82086"
      },
      "source": [
        "# MNIST: rescale the input data into the range [0,1]\n",
        "print(\"Fashion-MNIST\")\n",
        "print(\"Max value in initial dataset (train/test):\", np.max(x_mnist_fashion_train), np.max(x_mnist_fashion_test))\n",
        "print(\"Min value in initial dataset (train/test):\", np.min(x_mnist_fashion_train), np.min(x_mnist_fashion_test))\n",
        "x_mnist_fashion_train = x_mnist_fashion_train / max_grey_value  \n",
        "x_mnist_fashion_test = x_mnist_fashion_test / max_grey_value \n",
        "print(\"Max value in rescaled dataset (train/test):\", np.max(x_mnist_fashion_train), np.max(x_mnist_fashion_test))\n",
        "print(\"Min value in rescaled dataset (train/test):\", np.min(x_mnist_fashion_train), np.min(x_mnist_fashion_test))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fashion-MNIST\n",
            "Max value in initial dataset (train/test): 255 255\n",
            "Min value in initial dataset (train/test): 0 0\n",
            "Max value in rescaled dataset (train/test): 1.0 1.0\n",
            "Min value in rescaled dataset (train/test): 0.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cZuTQVecZJB",
        "outputId": "3b510c61-8087-4012-aae1-33b6dc0241df"
      },
      "source": [
        "# Constants\n",
        "INPUT_DIM_MNIST = x_mnist_train.shape[1]\n",
        "INPUT_DIM_MNIST_FASHION = x_mnist_fashion_train.shape[1]\n",
        "MNIST_NUMBER_CLASSES = y_mnist_train_one_hot.shape[1]\n",
        "MNIST_FASHION_NUMBER_CLASSES = y_mnist_fashion_train_one_hot.shape[1]\n",
        "print(\"MMNIST Input Shape {0}; MNIST Number Of Classes {1}\".format(INPUT_DIM_MNIST, MNIST_NUMBER_CLASSES))\n",
        "print(\"MMNIST Fashion Input Shape {0}; MNIST Fashion Number Of Classes {1}\".format(INPUT_DIM_MNIST_FASHION, MNIST_FASHION_NUMBER_CLASSES))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MMNIST Input Shape 784; MNIST Number Of Classes 10\n",
            "MMNIST Fashion Input Shape 784; MNIST Fashion Number Of Classes 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nWca9BqUmF3"
      },
      "source": [
        "## Exercise 2: No hidden layer (10 points)\n",
        "\n",
        "Define and fit a model without a hidden layer (since we will use multi-layer models later in this project, you can define a general constructor function for models with an arbitrary number of hidden layers already at this point). Note that in this miniproject there is no real test dataset and what is loaded as a test dataset is used for validation. First, implement 1.-3. for the MNIST dataset.  \n",
        "\n",
        "1. Implement the model with the following specifications: use the softmax activation for the output layer, use the categorical_crossentropy loss, choose stochastic gradient descent for the optimizer, and add the accuracy metric to the metrics. (5 pts)\n",
        "2. Train for as many epochs as needed to see no further decrease in the validation loss. (1 pt)\n",
        "3. Plot the learning curves resulting from the fitting procedure (a history object) using the function `plot_history` defined above. (1 pt)\n",
        "4. Repeat the above steps for fitting the network to the Fashion-MNIST dataset. (2 pts)\n",
        "5. Report the best validation accuracy achieved for each one of the datasets. Do you observe overfitting already for this simple model? Answer separetely for the MNIST dataset and Fashion-MNIST dataset. (1 pt) \n",
        "\n",
        "*Hint:* Read the keras docs, in particular [Getting started with the Keras Sequential model](https://keras.io/getting-started/sequential-model-guide/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0om4_uXUmF5"
      },
      "source": [
        "**Answer to Question 5** (max 2 sentences):<br/>\n",
        "*MNIST:*\n",
        "\n",
        "We see that the improvement of the validation accuracy levels out around 20 epochs.\n",
        "\n",
        "If overfitting, we should see the validation loss stopping to decrease (i.e. increasing). Furthermore, since there is a lot of training data for a models with only 7960 parameters it is unlikely that the model is overfitting.\n",
        "\n",
        "*Fashion-MNIST:*\n",
        "\n",
        "We see that the improvement of the validation accuracy levels out around after 75 epochs\n",
        "\n",
        "Same interpretation than MNIST regarding overfitting, even more Fashion-MNIST has been introduced as beeing \"harder\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgSYz8gAUmF5"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7vGd8ZORprP"
      },
      "source": [
        "#### Exercise 2.1\n",
        "Implement the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDk_lRLPUmF5",
        "outputId": "77320f98-3f7e-46f2-c318-0300277d2240"
      },
      "source": [
        "# Get number of columns in training data\n",
        "input_dim_mnist = x_mnist_train.shape[1]\n",
        "\n",
        "# Get number of classes\n",
        "mnist_classes_nb = y_mnist_train_one_hot.shape[1]\n",
        "\n",
        "# Use Keras sequential model\n",
        "model = Sequential()\n",
        "model.add(Dense(mnist_classes_nb, activation='relu', name=\"input_layer\",  input_shape=(input_dim_mnist,)))\n",
        "model.add(Dense(mnist_classes_nb, activation='softmax', name=\"output_layer\"))\n",
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.name_=\"model 2.1\"\n",
        "model.summary()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDsqMm-ETZqT"
      },
      "source": [
        "#### Exercise 2.2\n",
        "Train for as many epochs as needed to see no further decrease in the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "enKDEfdkTQ68",
        "outputId": "c9a5e3c8-1beb-496e-f974-07bbddd2a918"
      },
      "source": [
        "epochs = 100\n",
        "checkpoint_callback = ModelCheckpoint('./models/exercise-2.2/model.keras', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
        "stop_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "callbacks = [stop_callback, checkpoint_callback]\n",
        "\n",
        "history = model.fit(x_mnist_train, y_mnist_train_one_hot, validation_data=(x_mnist_test, y_mnist_test_one_hot), epochs=epochs, callbacks=callbacks, verbose=verbose)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4539 - accuracy: 0.5549 - val_loss: 0.5156 - val_accuracy: 0.8619\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.51564, saving model to ./models/exercise-2.2/model.keras\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4814 - accuracy: 0.8680 - val_loss: 0.3774 - val_accuracy: 0.8975\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.51564 to 0.37745, saving model to ./models/exercise-2.2/model.keras\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3711 - accuracy: 0.8948 - val_loss: 0.3292 - val_accuracy: 0.9101\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.37745 to 0.32923, saving model to ./models/exercise-2.2/model.keras\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3347 - accuracy: 0.9057 - val_loss: 0.3104 - val_accuracy: 0.9120\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.32923 to 0.31039, saving model to ./models/exercise-2.2/model.keras\n",
            "Epoch 5/100\n",
            "1731/1875 [==========================>...] - ETA: 0s - loss: 0.3161 - accuracy: 0.9118"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-3a9dc4676226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstop_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mnist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mnist_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mnist_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mnist_test_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6jIRPNeLR9X"
      },
      "source": [
        "#### Exercise 2.3\n",
        "\n",
        "Plot the learning curves resulting from the fitting procedure (a history object) using the function `plot_history` defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "VVP8kpKlJgmi",
        "outputId": "e0a569c0-54a4-4e39-af03-dc8b73817d71"
      },
      "source": [
        "plot_history(history, \"MNIST learning with no Hidden Layer\");"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jANnS4HqMROF"
      },
      "source": [
        "#### Exercise 2.4\n",
        "\n",
        "Repeat with the Fashion-MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw9b2nInUOcA"
      },
      "source": [
        "# Get number of columns in training data\n",
        "input_dim_fashion = x_mnist_fashion_train.shape[1]\n",
        "\n",
        "# Get number of classes\n",
        "fashion_classes_nb = y_mnist_fashion_train_one_hot.shape[1]\n",
        "\n",
        "#Define model callbacks\n",
        "checkpoint_callback = ModelCheckpoint('./models/exercise-2.4/model.keras', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
        "stop_callback = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "callbacks = [stop_callback, checkpoint_callback]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmvJqNFnUOcB",
        "outputId": "3d9f16cf-b52e-4d8a-88a8-1d43c9402aaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Use Keras sequential model\n",
        "model = Sequential()\n",
        "model.add(Dense(fashion_classes_nb, activation='relu', input_shape=(input_dim_fashion,)))\n",
        "model.add(Dense(fashion_classes_nb, activation='softmax'))\n",
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "zeS99WhhMW_-",
        "outputId": "f8f93d98-0a44-4569-92f0-2367da18c18f"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(x_mnist_fashion_train, y_mnist_fashion_train_one_hot, validation_data=(x_mnist_fashion_test, y_mnist_fashion_test_one_hot), epochs=epochs, callbacks=callbacks)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.3302 - accuracy: 0.5562 - val_loss: 0.6314 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.63140, saving model to ./models/exercise-2.4/model.keras\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5852 - accuracy: 0.8037 - val_loss: 0.5553 - val_accuracy: 0.8113\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.63140 to 0.55528, saving model to ./models/exercise-2.4/model.keras\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5154 - accuracy: 0.8260 - val_loss: 0.5197 - val_accuracy: 0.8205\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.55528 to 0.51965, saving model to ./models/exercise-2.4/model.keras\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4837 - accuracy: 0.8341 - val_loss: 0.5123 - val_accuracy: 0.8239\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.51965 to 0.51233, saving model to ./models/exercise-2.4/model.keras\n",
            "Epoch 5/100\n",
            " 865/1875 [============>.................] - ETA: 1s - loss: 0.4739 - accuracy: 0.8354"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-d4b90f527f10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mnist_fashion_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mnist_fashion_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mnist_fashion_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mnist_fashion_test_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYnfImWfNT9o"
      },
      "source": [
        "plot_history(history, \"Fashion-MNIST learning with no Hidden Layer \");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvUjwawMNfS9"
      },
      "source": [
        "We see that the improvement of the validation accuracy levels out around 75 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93JrKMECUmF5"
      },
      "source": [
        "## Exercise 3: One hidden layer, different optimizers (10 points)\n",
        "\n",
        "Train a network with one hidden layer and compare different optimizers for the MNIST dataset.\n",
        "\n",
        "1. Use one hidden layer with 128 units and the 'relu' activation. Use the [summary method](https://keras.io/api/models/model/#summary-method) to display your model in a compact way. (1 pt)\n",
        "2. Train the model for at least 50 epochs with different learning rates of stochastic gradient descent (SGD). What happens if the learning rate $\\eta$ is very large (for ex. $\\eta=1$), and very small (for ex. $\\eta=0.001$)? Comment on the fluctuations of the learning curve. (2 pts)\n",
        "3. Replace the stochastic gradient descent optimizer with the [Adam optimizer](https://keras.io/optimizers/#adam) (you can use the default learning rate). (1pt)\n",
        "4. Plot the learning curves of SGD with a good learning rate (i.e. in the range [0.01,0.1]) together with the learning curves of Adam in the same figure. Take care of a reasonable labeling of the curves in the plot. (1 pts)\n",
        "5. Explain the qualitative difference between the loss and accuracy curves with respect to signs of overfitting. Report the best validation accuracy achieved for SGD and Adam. Which one is better and why do you think so? (2 pts)\n",
        "6. Determine the indices of all test images that are misclassified by the fitted model and plot some of them using the function \n",
        "   `plot_some_samples`. (1 pt)\n",
        "\n",
        "Real-world datasets are labeled by some people and sometimes there are mistakes in the labeling. We will corrupt labels of the MNIST dataset artifically, and observe an overfitting to this noisy dataset with Adam. \n",
        "\n",
        "7. Take $ p = 0.2 $ fraction of the data points from the training dataset of MNIST and change their class labels randomly. (You can sample a random integer from 0 to 9 using `np.random.uniform` and `np.floor`). Train with Adam for 50 or 100 epochs. Plot the learning curves. Do you observe overfitting in the validation accuracy? Does it take longer to converge to perfect training accuracy compare to noise-free MNIST? (2 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqsjfxPdUmF5"
      },
      "source": [
        "**Answer to Question 2** (max 2 sentences): We can see in the diagrams that fluctuations of the learning curve are increasing with the learning rate (for small learning rates {0.01, 0.001} almost no fluctuations in the learning curve can be seen anymore and the shape of the learning curve is really smooth). This can be explained by the fact that with a small learning rates, the algorithm makes smaller steps, and so weights change less before correcting direction.\n",
        "\n",
        "**Answer to Question 5** (max 3 sentences): Adam is faster to learn but at the end they perform in the same way (so faster leaning, but similar performances). We can explain it, saying that the networks are the same, but in Adam case the learning rate is adapting. To get models of similar performances, we must stop learning when it begins to overfit (around 5 epochs for Adam).\n",
        "\n",
        "**Answer to Question 7** (max 2 sentences): The noisy dataset begins to overfit after around 5 epochs. The model is definetly overfitting to the noise in the noisy MNIST dataset. It takes much longer to converge towards the perfect training accuracy on the noisy MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqNAh2guUmF5"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8E46szjUOcC"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "\n",
        "def create_model(input_dim):\n",
        "    inputs = Input(shape=(input_dim,), name=\"input_layer\")\n",
        "    layer = Dense(128, activation='relu', name=\"hidden_layer\")(inputs)\n",
        "    outputs = Dense(mnist_classes_nb, activation='softmax', name=\"output_layer\")(layer)\n",
        "    #model = Model(inputs=inputs, outputs=outputs, name=\"Model Exercise 3.1\") # ValueError: 'Model Exercise 3.1/' is not a valid scope name\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52WnT_AcObgs"
      },
      "source": [
        "#### Exercise 3.1\n",
        "\n",
        "Use one hidden layer with 128 units and the 'relu' activation. Use the [summary method](https://keras.io/api/models/model/#summary-method) to display your model in a compact way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE8X5bTnUOcC",
        "outputId": "1f7bc9b0-5ce4-4e89-b71d-b891471cfbcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_model(input_dim_mnist)\n",
        "model.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "hidden_layer (Dense)         (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqZiIDyzdnWz"
      },
      "source": [
        "#### Exercise 3.2\n",
        "\n",
        "Train the model for at least 50 epochs with different learning rates of stochastic gradient descent (SGD). What happens if the learning rate   is very large (for ex.  =1), and very small (for ex.  =0.001)? Comment on the fluctuations of the learning curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrvvd0gcd7jh",
        "outputId": "7f7c4301-6516-406b-9a67-80594b5d0375"
      },
      "source": [
        "learning_rates = [10**(-e) for e in range(0,4)]\n",
        "histories = []\n",
        "models = []\n",
        "epochs = 50\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(\"Optimizing model with SGD (lr: {0})\".format(lr))\n",
        "    model = create_model(input_dim_mnist)\n",
        "    #mc = ModelCheckpoint('./models/exercise-3.2/model_sgd_lr-{0}.keras'.format(str(lr).replace('.',',')), monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
        "    model.compile(optimizer=SGD(lr=lr), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "    #history = model.fit(x_mnist_train, y_mnist_train_one_hot, validation_data=(x_mnist_test, y_mnist_test_one_hot), epochs=epochs, verbose=verbose, callbacks=[mc])\n",
        "    history = model.fit(x_mnist_train, y_mnist_train_one_hot, validation_data=(x_mnist_test, y_mnist_test_one_hot), epochs=epochs, verbose=verbose)\n",
        "    histories.append(history)\n",
        "    models.append(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizing model with SGD (lr: 1)\n",
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7947 - accuracy: 0.7631 - val_loss: 0.2836 - val_accuracy: 0.9236\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2719 - accuracy: 0.9279 - val_loss: 0.2082 - val_accuracy: 0.9429\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2038 - accuracy: 0.9440 - val_loss: 0.2227 - val_accuracy: 0.9421\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1803 - accuracy: 0.9521 - val_loss: 0.2069 - val_accuracy: 0.9441\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1634 - accuracy: 0.9566 - val_loss: 0.2421 - val_accuracy: 0.9407\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1630 - accuracy: 0.9573 - val_loss: 0.1830 - val_accuracy: 0.9567\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1378 - accuracy: 0.9634 - val_loss: 0.1913 - val_accuracy: 0.9553\n",
            "Epoch 8/50\n",
            "1657/1875 [=========================>....] - ETA: 0s - loss: 0.1405 - accuracy: 0.9636"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgZhZsnY-zs3"
      },
      "source": [
        "print(\"Learning on MNIST dataset\")\n",
        "for i in range(len(histories)):\n",
        "  history = histories[i]\n",
        "  lr = learning_rates[i]\n",
        "  plot_history(history, \"Learning rate {0}\".format(lr));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwlnJS6JFac4"
      },
      "source": [
        "#### Exercise 3.3\n",
        "\n",
        "Replace the stochastic gradient descent optimizer with the [Adam optimizer](https://keras.io/optimizers/#adam) (you can use the default learning rate)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkKPojMOF6wg"
      },
      "source": [
        "model_adam = create_model()\n",
        "adam_lr = 0.001\n",
        "mc = ModelCheckpoint('./models/exercise-3.3/model_adam_lr-{0}.keras'., monitor='val_loss', mode='min', save_best_only=True, verbose=verbose)\n",
        "model_adam.compile(optimizer=Adam(learning_rate=adam_lr), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "history_adam = model_adam.fit(x_mnist_train, y_mnist_train_one_hot, validation_data=(x_mnist_test, y_mnist_test_one_hot), epochs=epochs, verbose=verbose, callbacks=[mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80kW0NP1KA1U"
      },
      "source": [
        "plot_history(history_adam, \"MNIST learning with Adam (learning rate {0})\".format(adam_lr));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4nlIXiGL58O"
      },
      "source": [
        "#### Exercise 3.4\n",
        "\n",
        "Plot the learning curves of SGD with a good learning rate (i.e. in the range [0.01,0.1]) together with the learning curves of Adam in the same figure. Take care of a reasonable labeling of the curves in the plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu3ZMXLBUmF6"
      },
      "source": [
        "# This plotting routine might help you ...\n",
        "def comparison_plot(history_sgd, history_adam, label1, label2, title):\n",
        "    fig, ax1, ax2 = prepare_standardplot(title, \"epochs\")\n",
        "    ax1.plot(history_sgd.history['loss'], label=label1 + ' train')\n",
        "    ax1.plot(history_sgd.history['val_loss'], label=label1 + ' val')\n",
        "    ax1.plot(history_adam.history['loss'], label=label2 + ' train')\n",
        "    ax1.plot(history_adam.history['val_loss'], label=label2 + ' val')\n",
        "    ax2.plot(history_sgd.history['accuracy'], label=label1 + ' train')\n",
        "    ax2.plot(history_sgd.history['val_accuracy'], label=label1 + ' val')\n",
        "    ax2.plot(history_adam.history['accuracy'], label=label2 + ' train')\n",
        "    ax2.plot(history_adam.history['val_accuracy'], label=label2 + ' val')\n",
        "    finalize_standardplot(fig, ax1, ax2)\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJNmTC4fMl4i"
      },
      "source": [
        "sgd_lr = 0.1\n",
        "history_sgd = histories[learning_rates.index(sgd_lr)]\n",
        "comparison_plot(history_sgd, history_adam, \"SGD (LR {0})\".format(sgd_lr), \"Adam(LR {0})\".format(adam_lr), \"Optimizer Comparison\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmqo7WOOUOcE"
      },
      "source": [
        "#### Exercise 3.5\n",
        "Explain the qualitative difference between the loss and accuracy curves with respect to signs of overfitting. Report the best validation accuracy achieved for SGD and Adam. Which one is better and why do you think so?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnu424Vd9yZA",
        "tags": []
      },
      "source": [
        "from keras.models import load_model\n",
        "model_path = \"./models/exercise-3.2/model_sgd_lr-{0}.keras\".format(str(sgd_lr).replace('.',','))\n",
        "model_sgd = load_model(model_path, compile=True)\n",
        "err, acc = model_sgd.evaluate(x_mnist_test, y_mnist_test_one_hot, verbose=0)\n",
        "print(\"{path}: err: {err}, acc: {acc}\".format(path=model_path, err=err, acc=acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkvbFPGK9yZA"
      },
      "source": [
        "model_path = \"./models/exercise-3.3/model_adam_lr-{0}.keras\".format(str(adam_lr).replace('.',','))\n",
        "model_adam = load_model(model_path, compile=True)\n",
        "err, acc = model_adam.evaluate(x_mnist_test, y_mnist_test_one_hot, verbose=0)\n",
        "print(\"{name}: err: {err}, acc: {acc}\".format(name=model_path, err=err, acc=acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1pi3qoPUOcE"
      },
      "source": [
        "### Exercise 3.6\n",
        "Determine the indices of all test images that are misclassified by the fitted model and plot some of them using the function `plot_some_samples`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBRa0vEuUOcF"
      },
      "source": [
        "models = [model_sgd, model_adam]\n",
        "for model in models:\n",
        "    y_pred = model.predict_on_batch(x_mnist_test).argmax(axis=1)\n",
        "    indices = [i for i,v in enumerate(y_pred) if y_pred[i]!=y_mnist_test[i]]\n",
        "    x_wrongly_predicted = np.asarray([x_mnist_test[i] for i in indices])\n",
        "    y_wrongly_predicted = np.asarray([y_pred[i] for i in indices])\n",
        "    y_true_prediction = np.asarray([y_mnist_test[i] for i in indices])\n",
        "    plot_some_samples_cust(x_wrongly_predicted, y_true_prediction, y_wrongly_predicted, ncols=6, nrows=4);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpoF65jbOtM9"
      },
      "source": [
        "3.7) Add noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS7MoMXcx4Rt"
      },
      "source": [
        "p = 0.2\n",
        "mnist_traint_length = original_mnist_train_shape[0]\n",
        "indices = np.arange(mnist_traint_length)\n",
        "noise_number_mnist = int(mnist_traint_length*p)\n",
        "noisy_indices = np.random.choice(indices, noise_number_mnist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUxY_4NfsuSi"
      },
      "source": [
        "for index in noisy_indices:\n",
        "  class_index = np.floor(np.random.uniform(0,10))\n",
        "  vector = to_categorical(class_index, num_classes=mnist_classes_nb)\n",
        "  y_mnist_train_one_hot[index] = vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgvNFrjHWyE1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aKhbvpvPE7t"
      },
      "source": [
        "model.reset_states()\n",
        "model.compile(optimizer=Adam(learning_rate=adam_lr), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "history_adam_noisy = model.fit(x_mnist_train, y_mnist_train_one_hot, validation_data=(x_mnist_test, y_mnist_test_one_hot), epochs=100, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m75PnAPxQ7J8"
      },
      "source": [
        "plot_history(history_adam_noisy, \"Noisy MNIST learning with Adam (learning rate {0})\".format(adam_lr));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYwZzlrEc2i3"
      },
      "source": [
        "comparison_plot(history_adam, history_adam_noisy, \"MNIST Adam(LR {0})\".format(sgd_lr), \"Noisy MNIST Adam(LR {0})\".format(adam_lr), \"Optimizer Comparison\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpmARB73UOcG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b33M0ko9yZD"
      },
      "source": [
        "#### Exercise 3.7\n",
        "\n",
        "7. Take $ p = 0.2 $ fraction of the data points from the training dataset of MNIST and change their class labels randomly. (You can sample a random integer from 0 to 9 using `np.random.uniform` and `np.floor`). Train with Adam for 50 or 100 epochs. Plot the learning curves. Do you observe overfitting in the validation accuracy? Does it take longer to converge to perfect training accuracy compare to noise-free MNIST? (2 pts)<br/>\n",
        "**=> The training accuracy is increasing, starting from 80% and reaching around 90% after 100 episodes. The validation accuracy on the other hand is decreasing from 95% to around 80% after 100 episodes. The model is definetly overfitting to the noise in the shifted MNIST dataset. It takes much longer to converge towards the perfect training accuracy on the noisy MNIST dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zj54fsL9yZD"
      },
      "source": [
        "def unison_shuffle(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "# Calculate the number of samples that need to be replaced.\n",
        "length = int(np.floor(0.2 * len(y_mnist_train)))\n",
        "\n",
        "y_random = np.empty(0)\n",
        "for i in range(length):\n",
        "    y_random = np.append(y_random, np.floor(np.random.uniform(0,9.9)))\n",
        "\n",
        "# Replace the labels of the first n training samples with random lables.\n",
        "y_mnist_train[:length] = y_random\n",
        "\n",
        "# Shuffle the X and y data in order to spread the random labels equally over the dataset\n",
        "x_mnist_train_shuffled, y_mnist_train_shuffled = unison_shuffle(x_mnist_train, y_mnist_train)\n",
        "\n",
        "# One hot encoding\n",
        "y_mnist_train_shuffled_one_hot = to_categorical(y_mnist_train_shuffled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz7lUQQsUOcG"
      },
      "source": [
        "model = create_model()\n",
        "mc = ModelCheckpoint('./models/exercise-3.7/model.keras', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "history_adam = model.fit(x_mnist_train_shuffled, y_mnist_train_shuffled_one_hot, validation_data=(x_mnist_test, y_mnist_test_one_hot), epochs=100, validation_split=0.2, verbose=1, callbacks=[mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42hBiOltUOcG"
      },
      "source": [
        "plot_history(history_adam, \"Adam with LR 0.001 @ Permutated MNIST Dataset\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oENMCYod9yZD"
      },
      "source": [
        "## Exercise 4: Model performance as a function of number of hidden neurons (8 + 2 points)\n",
        "\n",
        "Since the MNIST dataset is almost perfectly solved already by a one-hidden-layer network in Exercise 3, we use the Fashion-MNIST dataset from now on to compare the performances of more complex models. In this exercise, we investigate how the best validation loss and accuracy depends on the number of hidden neurons in a single layer.\n",
        "\n",
        "1. Fit at least 4 models with different number of hidden neurons (i.e. width) between 10 and 1000 to the Fashion-MNIST dataset. Train with Adam for 50-100 epochs. (2 pts)\n",
        "2. Plot the best validation loss and accuracy versus the width. Is the observed trend in accordance with the [general approximation theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem)? Do you observe an overfitting due to the complexity of the wider networks with more parameters? Report the best validation accuracy. (2 pts)\n",
        "3. Choose $ p \\geq 0.5 $ fraction of the data points from the training dataset of Fashion-MNIST and change their class labels randomly as in Exercise 3. For this noisy Fashion-MNIST dataset, fit at least 4 models with different widths between 10 and 250. Train with Adam for at least 150 epochs. Plot the best validation loss and accuracy vs. width. (2 pts)\n",
        "4. BONUS: Add random Gaussian noise on the input pixels with mean 0 and variance between 0.01-0.5 and use the original labels. For this noisy Fashion-MNIST dataset, fit at least 4 models with different widths between 10 and 250. Train with Adam for at least 150 epochs. Plot the best validation loss and accuracy vs. width. (2 pts)\n",
        "5. Answer to the same questions in 2 for the noisy Fashion-MNIST dataset(s). Comment on the differences between width-performence curves for these two (or three) datasets. (2 pts)\n",
        "\n",
        "In this exercise we fit each model only for one initialization and random seed. In practice one would collect some statistics (e.g. 25-, 50-, 75-percentiles) for each layer size by fitting each model several times with different initializations and the random seeds. You may also want to do this here. It is a good exercise, but not mandatory as it takes quite a bit of computation time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcWkSkaj9yZE"
      },
      "source": [
        "**Answer to Question 2** (max 2 sentences):\n",
        "The Universal Approximation Theorem states that a neural network with one hidden layer and unlimited number of hidden neurons can approximate any continuous function for inputs within a specific range and this can also be observed with our example, since the best training accuracy is steadily increasing with the number of hidden neurons.\n",
        "We can see that our different models are overfitting and the overfitting increases with an increasing number of hidden neurons.\n",
        "\n",
        "**Answer to Question 5** (max 3 sentences): \n",
        "Although the training and validation accuracy of exercise 4.3's models is quite low (since the 50% of the training labels got changed), we can still see that the training accuracy rises significantly with the number of hidden neurons (From 12% to 26%). A neural network with many hidden nodes is still able to learn this highly dataset correctly and achieve a high training accuracy (in accordance with the universal approximation theorem).\n",
        "In exercise 4.4 we can see that fitting to this slightly noisy dataset still works pretty well, although the model is also overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqK_mkEu9yZE"
      },
      "source": [
        "#### Exercise 4 - Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPeXrSV4UOcH"
      },
      "source": [
        "def return_model_with_n_hidden_neurons(n_hidden_neurons):\n",
        "    # Get number of columns in training data\n",
        "    inputs = Input(shape=(INPUT_DIM,), name=\"input_layer\")\n",
        "    layer = Dense(n_hidden_neurons, activation='relu', name=\"hidden_layer\")(inputs)\n",
        "    outputs = Dense(10, activation='softmax', name=\"output_layer\")(layer)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=\"ex3.1\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "h98Y3tzsUOcH"
      },
      "source": [
        "import glob\n",
        "def plot_histories(base_path):\n",
        "    #print(base_path)\n",
        "    model_history_paths = glob.glob(base_path + '/*.npy')\n",
        "    for model_history_path in model_history_paths:\n",
        "        history=np.load(model_history_path, allow_pickle='TRUE').item()\n",
        "        plot_dict_history(history, model_history_path);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS4JtmhwUOcH"
      },
      "source": [
        "def load_metrics(base_path, numbers_of_hidden_neurons):\n",
        "    metrics = {\"x\": [], \"min_loss\": [], \"min_val_loss\": [], \"max_accuracy\": [], \"max_val_accuracy\": []}\n",
        "    for number_of_hidden_neurons in numbers_of_hidden_neurons:\n",
        "        model_history_path = '{0}/ANN-with-{1}-hidden-neurons.npy'.format(base_path, number_of_hidden_neurons)\n",
        "        history=np.load(model_history_path, allow_pickle='TRUE').item()\n",
        "        metrics[\"x\"].append(number_of_hidden_neurons)\n",
        "        metrics[\"min_loss\"].append(min(history[\"loss\"]))\n",
        "        metrics[\"min_val_loss\"].append(min(history[\"val_loss\"])) \n",
        "        metrics[\"max_accuracy\"].append(max(history[\"accuracy\"]))\n",
        "        metrics[\"max_val_accuracy\"].append(max(history[\"val_accuracy\"]))\n",
        "        #print(metrics)\n",
        "    return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HTIw2Wm7UOcI"
      },
      "source": [
        "def plot_metrics(metrics):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle('Validation loss and accuracy / Number of hidden neurons')\n",
        "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.3, hspace=None)\n",
        "    fig.set_figheight(6)\n",
        "    fig.set_figwidth(12)\n",
        "    ax1.set_xscale('log',base=10)\n",
        "    ax1.set_ylabel(\"Validation loss\")\n",
        "    ax1.set_xlabel(\"number of hidden neurons\")\n",
        "    ax1.plot(metrics[\"x\"], metrics[\"min_loss\"])\n",
        "    ax1.plot(metrics[\"x\"], metrics[\"min_val_loss\"])\n",
        "    ax2.set_xscale('log',base=10)\n",
        "    ax2.set_ylabel(\"Validation accuracy\")\n",
        "    ax2.set_xlabel(\"number of hidden neurons\")\n",
        "    ax2.plot(metrics[\"x\"], metrics[\"max_accuracy\"]);\n",
        "    ax2.plot(metrics[\"x\"], metrics[\"max_val_accuracy\"]);\n",
        "    finalize_standardplot(fig, ax1, ax2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKMbJRAKUOcI"
      },
      "source": [
        "#### Exercise 4.1 & 4.2\n",
        "Fit at least 4 models with different number of hidden neurons (i.e. width) between 10 and 1000 to the Fashion-MNIST dataset. Train with Adam for 50-100 epochs. (2 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VBguz98UOcI"
      },
      "source": [
        "base_path = \"./models/exercise-4.1\"\n",
        "numbers_of_hidden_neurons = [10, 50, 100, 500, 1000]\n",
        "already_trained = []\n",
        "number_of_epochs = 50\n",
        "verbose=2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzZnBC3L9yZE"
      },
      "source": [
        "for number_of_hidden_neurons in numbers_of_hidden_neurons:\n",
        "    # Since the training process sometimes break we need to manually restart it\n",
        "    # with the next network that has not been trained yet.\n",
        "    if number_of_hidden_neurons in already_trained:\n",
        "        continue;\n",
        "        \n",
        "    print(\"Training network with {} hidden neurons\".format(number_of_hidden_neurons))\n",
        "    model_path = '{0}/ANN-with-{1}-hidden-neurons.keras'.format(base_path, number_of_hidden_neurons)\n",
        "    model_history_path = '{0}/ANN-with-{1}-hidden-neurons.npy'.format(base_path, number_of_hidden_neurons)\n",
        "    \n",
        "    model = return_model_with_n_hidden_neurons(number_of_hidden_neurons)\n",
        "    mc = ModelCheckpoint('{0}/ANN-with-{1}-hidden-neurons.keras'.format(base_path, number_of_hidden_neurons), monitor='val_loss', mode='min', save_best_only=True, verbose=verbose)\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "    history = model.fit(x_mnist_fashion_train, y_mnist_fashion_train_one_hot, validation_data=(x_mnist_fashion_test, y_mnist_fashion_test_one_hot), epochs=number_of_epochs, validation_split=0.2, verbose=verbose, callbacks=[mc])\n",
        "    np.save(model_history_path, history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "uG-Lijk4UOcI"
      },
      "source": [
        "plot_histories(base_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GhXcvZoUOcI"
      },
      "source": [
        "plot_metrics(load_metrics(base_path, numbers_of_hidden_neurons))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M9ZGFtsUOcI"
      },
      "source": [
        "metrics = load_metrics(base_path, numbers_of_hidden_neurons)\n",
        "print(metrics[\"max_val_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt-x74BbUOcJ"
      },
      "source": [
        "#### Exercise 4.3\n",
        "Choose $ p \\geq 0.5 $ fraction of the data points from the training dataset of Fashion-MNIST and change their class labels randomly as in Exercise 3. For this noisy Fashion-MNIST dataset, fit at least 4 models with different widths between 10 and 250. Train with Adam for at least 150 epochs. Plot the best validation loss and accuracy vs. width. (2 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-gBY-GMUOcJ"
      },
      "source": [
        "def unison_shuffle(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "# Calculate the number of samples that need to be replaced.\n",
        "length = int(np.floor(0.5 * len(y_mnist_fashion_train)))\n",
        "\n",
        "y_random = np.empty(0)\n",
        "for i in range(length):\n",
        "    y_random = np.append(y_random, np.floor(np.random.uniform(0,9.9)))\n",
        "\n",
        "# Replace the labels of the first n training samples with random lables.\n",
        "y_mnist_fashion_train_noisy = y_mnist_fashion_train.copy()\n",
        "y_mnist_fashion_train_noisy[:length] = y_random\n",
        "\n",
        "# Shuffle the X and y data in order to spread the random labels equally over the dataset\n",
        "x_mnist_fashion_train_shuffled, y_mnist_fashion_train_noisy_shuffled = unison_shuffle(x_mnist_fashion_train, y_mnist_fashion_train_noisy)\n",
        "\n",
        "# One hot encoding\n",
        "y_mnist_fashion_train_noisy_shuffled_one_hot = to_categorical(y_mnist_fashion_train_noisy_shuffled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJnTdynCUOcJ"
      },
      "source": [
        "numbers_of_hidden_neurons = [10, 50, 100, 150, 200, 250] \n",
        "already_trained = []\n",
        "number_of_epochs = 150\n",
        "base_path = './models/exercise-4.3' \n",
        "verbose=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeHOQ5rJUOcJ"
      },
      "source": [
        "for number_of_hidden_neurons in numbers_of_hidden_neurons:\n",
        "    # Since the training process sometimes break we need to manually restart it\n",
        "    # with the next network that has not been trained yet.\n",
        "    if number_of_hidden_neurons in already_trained:\n",
        "        continue;\n",
        "        \n",
        "    print(\"--- Training network with {} hidden neurons ---\".format(number_of_hidden_neurons))\n",
        "    \n",
        "    model = return_model_with_n_hidden_neurons(number_of_hidden_neurons)\n",
        "    model_path = '{0}/ANN-with-{1}-hidden-neurons.keras'.format(base_path, number_of_hidden_neurons)\n",
        "    model_history_path = '{0}/ANN-with-{1}-hidden-neurons.npy'.format(base_path, number_of_hidden_neurons)\n",
        "    \n",
        "    mc = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, verbose=verbose)\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "    history = model.fit(x_mnist_fashion_train, y_mnist_fashion_train_noisy_shuffled_one_hot, validation_data=(x_mnist_fashion_test, y_mnist_fashion_test_one_hot), epochs=number_of_epochs, validation_split=0.2, verbose=verbose, callbacks=[mc])\n",
        "    \n",
        "    np.save(model_history_path, history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSEl4iFAUOcJ"
      },
      "source": [
        "plot_histories(base_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "oYXcRZV0UOcK"
      },
      "source": [
        "plot_metrics(load_metrics(base_path, numbers_of_hidden_neurons))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRQJHCh5UOcK"
      },
      "source": [
        "### Exercise 4.4\n",
        "Add random Gaussian noise on the input pixels with mean 0 and variance between 0.01-0.5 and use the original labels. For this noisy Fashion-MNIST dataset, fit at least 4 models with different widths between 10 and 250. Train with Adam for at least 150 epochs. Plot the best validation loss and accuracy vs. width. (2 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNxN4DRTUOcK"
      },
      "source": [
        "# Prepare data for exercise 4.4\n",
        "import math\n",
        "\n",
        "number_of_training_images = x_mnist_fashion_train.shape[0]\n",
        "number_of_input_features = x_mnist_fashion_train.shape[1]\n",
        "\n",
        "noise = np.random.normal(0,math.sqrt(0.1),(number_of_training_images, number_of_input_features))\n",
        "x_mnist_fashion_train_noisy = x_mnist_fashion_train + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlRFhH52UOcK"
      },
      "source": [
        "# Define hyperparameters for exercise 4.4\n",
        "numbers_of_hidden_neurons = [10, 50, 100, 150, 200, 250] \n",
        "already_trained = []\n",
        "number_of_epochs = 150\n",
        "base_path = './models/exercise-4.4' \n",
        "verbose=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEGqohzfUOcK"
      },
      "source": [
        "for number_of_hidden_neurons in numbers_of_hidden_neurons:\n",
        "    # Since the training process sometimes break we need to manually restart it\n",
        "    # with the next network that has not been trained yet.\n",
        "    if number_of_hidden_neurons in already_trained:\n",
        "        continue;\n",
        "        \n",
        "    print(\"--- Training network with {} hidden neurons ---\".format(number_of_hidden_neurons))\n",
        "    \n",
        "    model = return_model_with_n_hidden_neurons(number_of_hidden_neurons)\n",
        "    model_path = '{0}/ANN-with-{1}-hidden-neurons.keras'.format(base_path, number_of_hidden_neurons)\n",
        "    model_history_path = '{0}/ANN-with-{1}-hidden-neurons.npy'.format(base_path, number_of_hidden_neurons)\n",
        "    \n",
        "    mc = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True, verbose=verbose)\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "    history = model.fit(x_mnist_fashion_train_noisy, y_mnist_fashion_train_one_hot, validation_data=(x_mnist_fashion_test, y_mnist_fashion_test_one_hot), epochs=number_of_epochs, validation_split=0.2, verbose=2, callbacks=[mc])\n",
        "    \n",
        "    np.save(model_history_path, history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUHkBCTuUOcK"
      },
      "source": [
        "plot_histories(base_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "NPzqei2OUOcL"
      },
      "source": [
        "plot_metrics(load_metrics(base_path, numbers_of_hidden_neurons))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2Gb7mgSUmF7"
      },
      "source": [
        "## Exercise 5: Going deeper: tricks and regularization (10 + 2 points)\n",
        "\n",
        "Adding hidden layers to a deep network does not necessarily lead to a straight-forward improvement of performance. We use Fashion-MNIST dataset in this exercise.  \n",
        "\n",
        "1. Choose a width $ h $ between 50-200 and use at least two hidden layers with $ h $ hidden neurons (each) and train the network for at least 150 epochs. (2 pts)\n",
        "2. Plot the learning curves and report the best validation accuracy. Do you observe overfitting? (2 pts)\n",
        "3. Keep the network at the same size. Use a very large l2 regularization $\\lambda$ (for ex. $\\lambda=1$) and a small one (for ex. $\\lambda=0.001$) on kernel weights and report the validation accuracies. What do you observe?  (2 pts)\n",
        "4. Turn off the $ \\ell_2 $ regularization and use a large dropout rate (for ex. 0.5) and a small one (for ex. 0.05) at all hidden layers and report the validation accuracies. What do you observe? (2 pts)\n",
        "5. BONUS: Try built-in data augmentation methods as a way to regularize: this may include horizontal flipping of the images or small rotations. You can use built-in methods in Keras. Report the augmentation method you used and the best validation accuracy. (2 pts)\n",
        "\n",
        "Note that one needs to cross-validate to find the right regularization parameter for the model you chose and for the dataset at hand. However we do not enforce this hyperparameter search as it takes long computation times but it is a good practice if you try it here. \n",
        "\n",
        "6. Compare the validation accuracies resulting from your attempts to reduce overfitting. Did you improve the validation accuracy? If not, comment on the possible sources of failure. (2 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzX8ezheUmF7"
      },
      "source": [
        "**Answer to Question 2** (max 1 sentence):<br/>\n",
        "Overfitting can be observed in the training process since the loss is decreasing but the validation loss is increasing and the validation accuracy levels out after 25 epochs although the training accuracy still keeps increasing.\n",
        "\n",
        "Best validation accuracy: 0.8906999826431274\n",
        "\n",
        "**Answer to Question 3** (max 2 sentences): \n",
        "\n",
        "**Answer to Question 4** (max 2 sentences): \n",
        "\n",
        "**Answer to Question 5 (BONUS)** (max 2 sentences): \n",
        "\n",
        "**Answer to Question 6** (max 2 sentences): "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3v2V_woX-r4"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0P5vrtGYmcO"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc6JyZi7X52z"
      },
      "source": [
        "def return_new_model (dropout_rate = 0, l2_regularization_parameter = 0):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, activation='relu', input_shape=(INPUT_DIM_MNIST_FASHION,), kernel_regularizer=regularizers.l1_l2(l1=0, l2=l2_regularization_parameter)))\n",
        "  if(dropout_rate > 0):\n",
        "      model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(128, activation='relu', input_shape=(INPUT_DIM_MNIST_FASHION,), kernel_regularizer=regularizers.l1_l2(l1=0, l2=l2_regularization_parameter)))\n",
        "  if(dropout_rate > 0):\n",
        "    model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(MNIST_FASHION_NUMBER_CLASSES, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSQJfhZVUmF8"
      },
      "source": [
        "#### Exercise 5.1\n",
        "Choose a width $ h $ between 50-200 and use at least two hidden layers with $ h $ hidden neurons (each) and train the network for at least 150 epochs.\n",
        "#### Exercise 5.2\n",
        "Plot the learning curves and report the best validation accuracy. Do you observe overfitting?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU6_9-HSUmF8"
      },
      "source": [
        "model = return_new_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIB-98huJxhQ"
      },
      "source": [
        "def train_model(model, x_train, y_train, x_test, y_test, model_path, number_of_epochs):\n",
        "  mc = ModelCheckpoint(\"{0}.keras\".format(model_path), monitor='val_loss', mode='min', save_best_only=True, verbose=verbose)\n",
        "  model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "  history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=number_of_epochs, verbose=verbose, callbacks=[mc])\n",
        "  np.save(\"{0}.npy\".format(model_path), history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M669P181U1sV"
      },
      "source": [
        "model_5_1 = return_new_model()\n",
        "base_path = './models/exercise-5.1/model'\n",
        "history_path = \"{0}.npy\".format(base_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91maQWSffBqq"
      },
      "source": [
        "train_model(model_5_1, x_mnist_fashion_train, y_mnist_fashion_train_one_hot, x_mnist_fashion_test, y_mnist_fashion_test_one_hot, base_path, number_of_epochs=150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9xmd8hLh-Sg"
      },
      "source": [
        "history = np.load(history_path, allow_pickle=True).item()\n",
        "plot_history_cust(history, history_path);\n",
        "print(\"Best validation accuracy: {0}\".format(max(history[\"val_accuracy\"])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9nh4tRimYD8"
      },
      "source": [
        "#### Exercise 5.3\n",
        "Keep the network at the same size. Use a very large l2 regularization $\\lambda$ (for ex. $\\lambda=1$) and a small one (for ex. $\\lambda=0.001$) on kernel weights and report the validation accuracies. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCillQwsbhkF"
      },
      "source": [
        "model_5_3_1 = return_new_model (dropout_rate = 0, l2_regularization_parameter = 1)\n",
        "model_5_3_1.summary()\n",
        "base_path = './models/exercise-5.3/model_1'\n",
        "history_path = \"{0}.npy\".format(base_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlPV7eFpbMCN"
      },
      "source": [
        "train_model(model_5_3_1, x_mnist_fashion_train, y_mnist_fashion_train_one_hot, x_mnist_fashion_test, y_mnist_fashion_test_one_hot, base_path, number_of_epochs=150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMFxyOabgpSD"
      },
      "source": [
        "history = np.load(history_path, allow_pickle=True).item()\n",
        "plot_history_cust(history, history_path);\n",
        "print(\"Best validation accuracy: {0}\".format(max(history[\"val_accuracy\"])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oXWrF26bBFP"
      },
      "source": [
        "model_5_3_2 = return_new_model (dropout_rate = 0, l2_regularization_parameter = 0.001)\n",
        "model_5_3_2.summary()\n",
        "base_path = './models/exercise-5.3/model_2'\n",
        "history_path = \"{0}.npy\".format(base_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgNRRoH9bQ1F"
      },
      "source": [
        "train_model(model_5_3_2, x_mnist_fashion_train, y_mnist_fashion_train_one_hot, x_mnist_fashion_test, y_mnist_fashion_test_one_hot, base_path, number_of_epochs=150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ujQc6e6g_dn"
      },
      "source": [
        "history = np.load(history_path, allow_pickle=True).item()\n",
        "plot_history_cust(history, history_path);\n",
        "print(\"Best validation accuracy: {0}\".format(max(history[\"val_accuracy\"])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9httDcZInLhz"
      },
      "source": [
        "#### Exercise 5.4\n",
        "Turn off the $ \\ell_2 $ regularization and use a large dropout rate (for ex. 0.5) and a small one (for ex. 0.05) at all hidden layers and report the validation accuracies. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL30QHhknfj3"
      },
      "source": [
        "model_5_4_1 = return_new_model(dropout_rate = 0.5, l2_regularization_parameter = 0)\n",
        "base_path = './models/exercise-5.4/model_1'\n",
        "history_path = \"{0}.npy\".format(base_path)\n",
        "model = return_new_model(dropout_rate = 0.5, l2_regularization_parameter = 0)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7IwtMkekua2"
      },
      "source": [
        "train_model(model_5_4_1, x_mnist_fashion_train, y_mnist_fashion_train_one_hot, x_mnist_fashion_test, y_mnist_fashion_test_one_hot, base_path, number_of_epochs=150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UXNysNKoXgm"
      },
      "source": [
        "history = np.load(history_path, allow_pickle=True).item()\n",
        "plot_history_cust(history, history_path);\n",
        "print(\"Best validation accuracy: {0}\".format(max(history[\"val_accuracy\"])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcXRKvfpjpiU"
      },
      "source": [
        "model_5_4_2 = return_new_model(dropout_rate = 0.05, l2_regularization_parameter = 0)\n",
        "base_path = './models/exercise-5.4/model_2'\n",
        "history_path = \"{0}.npy\".format(base_path)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_bc8X6FrrCU"
      },
      "source": [
        "train_model(model_5_4_2, x_mnist_fashion_train, y_mnist_fashion_train_one_hot, x_mnist_fashion_test, y_mnist_fashion_test_one_hot, base_path, number_of_epochs=150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vALV4yhRoRlN"
      },
      "source": [
        "history = np.load(history_path, allow_pickle=True).item()\n",
        "plot_history_cust(history, history_path);\n",
        "print(\"Best validation accuracy: {0}\".format(max(history[\"val_accuracy\"])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsqM3VfdzBTP"
      },
      "source": [
        "#### Exercise 5.5\n",
        "\n",
        "BONUS: Try built-in data augmentation methods as a way to regularize: this may include horizontal flipping of the images or small rotations. You can use built-in methods in Keras. Report the augmentation method you used and the best validation accuracy. (2 pts)\n",
        "\n",
        "Note that one needs to cross-validate to find the right regularization parameter for the model you chose and for the dataset at hand. However we do not enforce this hyperparameter search as it takes long computation times but it is a good practice if you try it here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6K6G_nuzRAT"
      },
      "source": [
        "#### Exercise5.6. \n",
        "\n",
        "Compare the validation accuracies resulting from your attempts to reduce overfitting. Did you improve the validation accuracy? If not, comment on the possible sources of failure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDYfqS_MUmF9"
      },
      "source": [
        "## Exercise 6: Convolutional neural networks (CNNs) (10 points)\n",
        "\n",
        "Convolutional neural networks have an inductive bias that is well adapted to image classification. \n",
        "\n",
        "1. Design a convolutional neural network and train it without using explicit regularizers. (2 pts)\n",
        "2. Try to improve the best validation scores of the model by experiment with batch_normalization layers, dropout layers and l2-regularization on weights (kernels) and biases. (4 pts)\n",
        "3. After you have found good settings, plot the learning curves for both models, naive (=no tricks/regularization) and tuned (=tricks + regularized) together in a comparison plot. (2pts)\n",
        "4. How does the CNN performance compare to the so far best performing (deep) neural network model? (2 pts)\n",
        "\n",
        "*Hint:* You may get valuable inspiration from the keras [examples](https://keras.io/examples/), [for example](https://keras.io/examples/vision/mnist_convnet/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUbPDPV_UmF9"
      },
      "source": [
        "**Answer to Question 4**: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dXDw80UmF9"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQxciXbRm-aa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}